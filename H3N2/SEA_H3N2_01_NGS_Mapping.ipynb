{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGS mapping  \n",
    "  \n",
    "This jupyter notebook maps the raw FASTQ sequencing reads of all samples to the given reference fasta (H3N2-Bris07 full genome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# load custom flu and ngs libraries \n",
    "laeb_lib = expanduser(\"../python_lib\") # folder where custom libraries are saved \n",
    "fc = SourceFileLoader('fc', \"%s/flu_common.py\"%(laeb_lib)).load_module()\n",
    "ngs = SourceFileLoader('ngs', \"%s/laeb_ngs_pipeline.py\"%(laeb_lib)).load_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "# file path to data folder - fastq files to be analysed must be in {data folder}/raw\n",
    "data_folder = './data' \n",
    "# reference fasta file name (should be placed in input_folder)\n",
    "ref_fasta_fname = './input/H3N2_Bris07.fasta' \n",
    "# CSV file containing the CDR regions of each gene segment (numbering should be based on that of the given reference sequence)\n",
    "cds_coords = \"./input/CDS_H3N2_Bris07.csv\"\n",
    "# primer coordinates (sequence numbering must be based on given reference sequence)\n",
    "primer_coords = \"./input/H3N2_primer_coords.csv\"\n",
    "# file path to metadata file. \n",
    "meta_fname = './input/metadata.csv' \n",
    "\n",
    "# mapping options\n",
    "trimmomatic_fpath = expanduser('~/opt/anaconda3/pkgs/trimmomatic-0.39-1/share/trimmomatic-0.39-1/') # file path to trimmomatic\n",
    "threadnum = 4 # number of CPU threads for parallelization \n",
    "base_qual_threshold = 20 # minimum accepted base quality \n",
    "max_indel_prop = 0.05 # max tolerable proportion of indels wrt read length \n",
    "max_indel_abs = 10 # max tolerable absolute number of indels \n",
    "\n",
    "# variant calling options\n",
    "Query_HAnum_subtype = 'absH3' # query HA numbering subtype (i.e. numbering based on CDR HA protein )\n",
    "HAnum_subtype = 'H3' # reporting HA numbering subtype\n",
    "subtype_ant = 'H3ant'  # HA canonical antigenic site of interest \n",
    "min_cov = 100 # minimum coverage \n",
    "min_var_freq = 0\n",
    "min_var_prop = 0.02 # minimum variant proportion \n",
    "err_tol = 0.01 # threshold to which variant called could result from base calling error \n",
    "min_breadth = 0.7 # min breadth of gene segment to be mapped for further analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and functions \n",
    "\n",
    "This cell perform several initialisation procedures, including: \n",
    " - defining parameters needed by the pipeline (e.g. gene segment length, etc.) and initialise to get CDR regions of each protein.\n",
    " - defining dataframe for HA numbering conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initialising CDS coordinates...\n",
      "\n",
      "Check translated protein sequences...\n",
      "PB2 MERIKELRNLMSQSRTREILTKTTVDHMAIIKKYTSGRQEKNPSLRMKWMMAMKYPITADKRITEMVPERNEQGQTLWSKMSDAGSDRVMVSPLAVTWWNRNGPVTSTVHYPKVYKTYFDKVERLKHGTFGPVHFRNQVKIRRRVDINPGHADLSAKEAQDVIMEVVFPNEVGARILTSESQLTITKEKKEELRDCKISPLMVAYMLERELVRKTRFLPVAGGTSSIYIEVLHLTQGTCWEQMYTPGGGVRNDDVDQSLIIAARNIVRRAAVSADPLASLLEMCHSTQIGGTRMVDILRQNPTEEQAVDICKAAMGLRISSSFSFGGFTFKRTSGSSVKKEEEVLTGNLQTLKIRVHEGYEEFTMVGKRATAILRKATRRLVQLIVSGRDEQSIAEAIIVAMVFSQEDCMIKAVRGDLNFVNRANQRLNPMHQLLRHFQKDAKVLFQNWGVEHIDSVMGMIGVLPDMTPSTEMSMRGIRVSKMGVDEYSSTERVVVSIDRFLRVRDQRGNVLLSPEEVSETQGTERLTITYSSSMMWEINGPESVLVNTYQWIIRNWEAVKIQWSQNPAMLYNKMEFEPFQSLVPKAIRSQYSGFVRTLFQQMRDVLGTFDTTQIIKLLPFAAAPPKQSRMQFSSLTVNVRGSGMRILVRGNSPVFNYNKTTKRLTILGKDAGTLIEDPDESTSGVESAVLRGFLIIGKEDRRYGPALSINELSNLAKGEKANVLIGQGDVVLVMKRKRDSSILTDSQTATKRIRMAIN*\n",
      "PB1 MDVNPTLLFIKVPAQNAISTTFPYTGDPPYSHGTGTGYTMDTVNRTHQYSEKGKWTTNTETGAPQLNPIDGPLPEDNEPSGYAQTDCVLEAMAFLEESHPGIFENSCLETMEAVQQTRVDKLTQGRQTYDWTLNRNQPAATALANTIEVFRSNGLTANESGRLIDFLKDVMESMDKEEMEITTHFQRKRRVRDNMTKKMVTQRTIGKKKQRVNKRGYLIRALTLNTMTKDAERGKLKRRAIATPGMQIRGFVYFVETLARSICEKLEQSGLPVGGNEKKAKLANVVRKMMTNSQDTELSFTITGDNTKWNENQNPRMFLAMITYITKNQPEWFRNILSIAPIMFSNKMARLGKGYMFESKRMKLRTQIPAEMLASVDLKYFNESTRKKIEKIRPLLIDGTASLSPGMMMGMFNMLSTVLGVSILNLGQKKYTKTTYWWDGLQSSDDFALIVNAPNHEGIQAGVDRFYRTCKLVGINMSKKKSYINKTGTFEFTSFFYRYGFVANFSMELPSFGVSGINESADMSIGVTVIKNNMINNDLGPATAQMALQLFIKDYRYTYRCHRGDTQIQTRRSFELKKLWDQTQSRAGLLVSDGGPNLYNIRNLHIPEVCLKWELMDENYRGRLCNPLNPFVSHKEIESVNNAVVMPAHGPAKSMEYDAVATTHSWIPKRNRSILNTSQRGILEDEQMYQKCCNLFEKFFPSSSYRRPIGISSMVEAMVSRARIDARIDFESGRIKKEEFSEIMKICSTIEELRRQK*\n",
      "PB1-F2 MEQEQGTPWTQSTEHTNIQRKGSGRQIQKLGHPNSTQLMDHYLRIMNQVDMHKQTVSWRLWPSLKNPTQVSLRTHALKQWKPFNRQGWTN*\n",
      "PA MEDFVRQCFNPMIVELAEKAMKEYGEDLKIETNKFAAICTHLEVCFMYSDFHFINEQGESIVVELDDPNALLKHRFEIIEGRDRTMAWTVVNSICNTTGAGKPKFLPDLYDYKENRFIEIGVTRREVHIYYLEKANKIKSENTHIHIFSFTGEEMATKADYTLDEESRARIKTRLFTIRQEMANRGLWDSFRQSERGEETIEEKFEITGTMRRLADQSLPPNFSCLENFRAYVDGFEPNGCIEGKLSQMSKEVNAQIEPFLKTTPRPIKLPNGPPCYQRSKFLLMDALKLSIEDPSHEGEGIPLYDAIKCIKTFFGWKEPYIVKPHEKGINSNYLLSWKQVLSELQDIENEEKIPRTKNMKKTSQLKWALGENMAPEKVDFENCRDISDLKQYDSDEPELRSLSSWIQNEFNKACELTDSVWIELDEIGEDVAPIEHIASMRRNYFTAEVSHCRATEYIMKGVYINTALLNASCAAMDDFQLIPMISKCRTKEGRRKTNLYGFIIKGRSHLRNDTDVVNFVSMEFSLTDPRLEPHKWEKYCVLEIGDMLLRNAIGQISRPMFLYVRTNGTSKVKMKWGMEMRRCLLQSLQQIESMIEAESSVKEKDMTKEFFENKSEAWPIGESPKGVEEGSIGKVCRTLLAKSVFNSLYASPQLEGFSAESRKLLLVVQALRDNLEPGTFDLGGLYEAIEECLINDPWVLLNASWFNSFLTHALK*\n",
      "PA-X MEDFVRQCFNPMIVELAEKAMKEYGEDLKIETNKFAAICTHLEVCFMYSDFHFINEQGESIVVELDDPNALLKHRFEIIEGRDRTMAWTVVNSICNTTGAGKPKFLPDLYDYKENRFIEIGVTRREVHIYYLEKANKIKSENTHIHIFSFTGEEMATKADYTLDEESRARIKTRLFTIRQEMANRGLWDSFVSPKEAKKQLKKNLKSQELCVGLPTKVSHRTSPALRILEPMWMDSNRTAALRASFLKCPKK*\n",
      "HA MKTIIALSYILCLVFTQKLPGNDNSTATLCLGHHAVPNGTIVKTITNDQIEVTNATELVQSSSTGEICDSPHQILDGENCTLIDALLGDPQCDGFQNKKWDLFVERSKAYSNCYPYDVPDYASLRSLVASSGTLEFNNESFNWTGVTQNGTSSACIRRSNNSFFSRLNWLTHLKFKYPALNVTMPNNEKFDKLYIWGVHHPGTDNDQIFLYAQASGRITVSTKRSQQTVIPNIGSRPRVRNIPSRISIYWTIVKPGDILLINSTGNLIAPRGYFKIRSGKSSIMRSDAPIGKCNSECITPNGSIPNDKPFQNVNRITYGACPRYVKQNTLKLATGMRNVPEKQTRGIFGAIAGFIENGWEGMVDGWYGFRHQNSEGIGQAADLKSTQAAIDQINGKLNRLIGKTNEKFHQIEKEFSEVEGRIQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTKKQLRENAEDMGNGCFKIYHKCDNACIGSIRNGTYDHDVYRDEALNNRFQIKGVELKSGYKDWILWISFAISCFLLCVALLGFIMWACQKGNIRCNICI*\n",
      "NP MASQGTKRSYEQMETDGDRQNATEIRASVGKMIDGIGRFYIQMCTELKLSDHEGRLIQNSLTIEKMVLSAFDERRNKYLEEHPSAGKDPKKTGGPIYRRVDGKWMRELVLYDKEEIRRIWRQANNGEDATSGLTHIMIWHSNLNDATYQRTRALVRTGMDPRMCSLMQGSTLPRRSGAAGAAVKGIGTMVMELIRMVKRGINDRNFWRGENGRKTRSAYERMCNILKGKFQTAAQRAMVDQVRESRNPGNAEIEDLIFLARSALILRGSVAHKSCLPACAYGPAVSSGYDFEKEGYSLVGIDPFKLLQNSQIYSLIRPNENPAHKSQLVWMACHSAAFEDLRLLSFIRGTKVSPRGKLSTRGVQIASNENMDNMGSSTLELRSGYWAIRTRSGGNTNQQRASAGQTSVQPTFSVQRNLPFEKSTIMAAFTGNTEGRTSDMRAEIIRMMEGAKPEEVSFRGRGVFELSDEKATNPIVPSFDMSNEGSYFFGDNAEEYDN*\n",
      "NA MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPPNNQVMLCEPTIIERNITEIVYLTNTTIEKEICPKLAEYRNWSKPQCDITGFAPFSKDNSIRLSAGGDIWVTREPYVSCDPDKCYQFALGQGTTLNNVHSNDTVRDRTPYRTLLMNELGVPFHLGTKQVCIAWSSSSCHDGKAWLHVCITGDDKNATASFIYNGRLVDSIVSWSKEILRTQESECVCINGTCTVVMTDGSASGKADTKILFIEEGKIVHTSTLSGSAQHVEECSCYPRYPGVRCVCRDNWKGSNRPIVDINIKDHSTVSSYVCSGLVGDTPRKNDSSSSSHCLDPNNEEGGHGVKGWAFDDGNDVWMGRTISEKSRLGYETFKVIEGWSNPKSKLQINRQVIVDRGNRSGYSGIFSVEGKSCINRCFYVELIRGRKEETEVLWTSNSIVVFCGTSGTYGTGSWPDGADINLMPI*\n",
      "M1 MSLLTEVETYVLSIVPSGPLKAEIAQRLEDVFAGKNTDLEALMEWLKTRPILSPLTKGILGFVFTLTVPSERGLQRRRFVQNALNGNGDPNNMDKAVKLYRKLKREITFHGAKEIALSYSAGALASCMGLIYNRMGAVTTEVAFGLVCATCEQIADSQHRSHRQMVATTNPLIRHENRMVLASTTAKAMEQMAGSSEQAAEAMEIASQARQMVQAMRAIGTHPSSSTGLRDDLLENLQTYQKRMGVQMQRFK*\n",
      "M2 MSLLTEVETPIRNEWGCRCNDSSDPLVVAANIIGILHLILWILDRLFFKCVYRLFKHGLKRGPSTEGVPESMREEYRKEQQNAVDADDSHFVSIELE*\n",
      "NEP MDSNTVSSFQCLLFQDILLRMSKMQLGSSSEDLNGMITQFESLKIYRDSLGEAVMRMGDLHLLQNRNGKWREQLGQKFEEIRWLIEEVRHRLKTTENSFEQITFMQALQLLFEVEQEIRTFSFQLI*\n",
      "NS1 MDSNTVSSFQVDCFLWHIRKQVVDQELSDAPFLDRLRRDQRSLRGRGNTLGLDIKAATHVGKQIVEKILKEESDEALKMTMVSTPASRYITDMTIEELSRNWFMLMPKQKVEGPLCIRMDQAIMEKNIMLKANFSVIFDRLETIVLLRAFTEEGAIVGEISPLPSFPGHTIEDVKNAIGVLIGGLEWNDNTVRVSKNLQRFAWRSSNENGGPPLTPKQKREMARTARSKV*\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th>nuc</th>\n",
       "      <th>protein</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1-PB2</th>\n",
       "      <th>1</th>\n",
       "      <th>PB2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>PB2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>PB2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>PB2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>PB2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   aa  frame\n",
       "gene  nuc protein           \n",
       "1-PB2 1   PB2       1      1\n",
       "      2   PB2       1      2\n",
       "      3   PB2       1      3\n",
       "      4   PB2       2      1\n",
       "      5   PB2       2      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H3</th>\n",
       "      <th>absH1pdm</th>\n",
       "      <th>absH5</th>\n",
       "      <th>H1N1pdm</th>\n",
       "      <th>H5</th>\n",
       "      <th>H5c221</th>\n",
       "      <th>H1ant</th>\n",
       "      <th>H3ant</th>\n",
       "      <th>RBS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absH3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       H3  absH1pdm  absH5  H1N1pdm  H5  H5c221 H1ant H3ant  RBS\n",
       "absH3                                                           \n",
       "1.0   NaN       1.0    1.0      NaN NaN     NaN   NaN   NaN    0\n",
       "2.0   NaN       2.0    2.0      NaN NaN     NaN   NaN   NaN    0\n",
       "3.0   NaN       3.0    3.0      NaN NaN     NaN   NaN   NaN    0\n",
       "4.0   NaN       4.0    4.0      NaN NaN     NaN   NaN   NaN    0\n",
       "5.0   NaN       5.0    5.0      NaN NaN     NaN   NaN   NaN    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# presets \n",
    "reffasta = ref_fasta_fname\n",
    "\n",
    "# initialise\n",
    "gene_to_proteinorf, influenza_gene_len, sorted_refnames, nucpos_shift = ngs.initialisation(cds_coords, reffasta, laeb_lib)\n",
    "display (gene_to_proteinorf.head())\n",
    "\n",
    "ha_numbering_conversion = pd.read_csv(expanduser('%s/HA_numbering_conversion.csv'%(laeb_lib)),\n",
    "                                      na_values='-')\n",
    "ha_numbering_conversion = ha_numbering_conversion.set_index(Query_HAnum_subtype)\n",
    "display (ha_numbering_conversion.head())\n",
    "\n",
    "all_bases = ['A', 'T', 'G', 'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read metadata\n",
    "\n",
    "Sample IDs are parsed from metadata file under the header \"sampid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>enrolD</th>\n",
       "      <th>ct</th>\n",
       "      <th>SampleType</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>enrol-onset</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>patch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T0_T_S517_N701_R</th>\n",
       "      <td>R1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>T</td>\n",
       "      <td>1205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1/8/07</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T1_N_S517_N702_R</th>\n",
       "      <td>R2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "      <td>1205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1/8/07</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T2_T_S517_N703_R</th>\n",
       "      <td>R3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>T</td>\n",
       "      <td>1205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1/8/07</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T3_T_S517_N704_R</th>\n",
       "      <td>R4</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>T</td>\n",
       "      <td>1205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1/8/07</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T4_T_S517_N705_R</th>\n",
       "      <td>R5</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>T</td>\n",
       "      <td>1205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1/8/07</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           idx  enrolD  ct SampleType  subject_id  \\\n",
       "sampid                                                              \n",
       "H3N2_1205_T0_T_S517_N701_R  R1       0  26          T        1205   \n",
       "H3N2_1205_T1_N_S517_N702_R  R2       1  25          N        1205   \n",
       "H3N2_1205_T2_T_S517_N703_R  R3       2  30          T        1205   \n",
       "H3N2_1205_T3_T_S517_N704_R  R4       3  29          T        1205   \n",
       "H3N2_1205_T4_T_S517_N705_R  R5       4  28          T        1205   \n",
       "\n",
       "                            enrol-onset    date  age  timepoint  patch  \n",
       "sampid                                                                  \n",
       "H3N2_1205_T0_T_S517_N701_R          6.0  1/8/07    2        6.0      0  \n",
       "H3N2_1205_T1_N_S517_N702_R          6.0  1/8/07    2        7.0      0  \n",
       "H3N2_1205_T2_T_S517_N703_R          6.0  1/8/07    2        8.0      0  \n",
       "H3N2_1205_T3_T_S517_N704_R          6.0  1/8/07    2        9.0      0  \n",
       "H3N2_1205_T4_T_S517_N705_R          6.0  1/8/07    2       10.0      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metadata \n",
    "## metadata must have 'sampid' header which is used as sample identifier \n",
    "meta_df = pd.read_csv(meta_fname)\n",
    "\n",
    "sorted_sampid = sorted(set(meta_df['sampid']))\n",
    "meta_df['timepoint'] = meta_df['enrolD']+meta_df['enrol-onset']\n",
    "\n",
    "meta_df = meta_df.sort_values(by=['subject_id', 'timepoint']).set_index('sampid')\n",
    "meta_df['patch'] = 0\n",
    "meta_df.at[meta_df.index.str.contains(r'_P$'), 'patch'] = 1\n",
    "\n",
    "display (meta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate dataframe of input FASTQ files...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampid</th>\n",
       "      <th>read</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">H3N2_1205_T0_T_S517_N701_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">H3N2_1205_T1_N_S517_N702_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T2_T_S517_N703_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T2_T_S517_N703_R_S3_L001_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             fpath\n",
       "sampid                     read                                                   \n",
       "H3N2_1205_T0_T_S517_N701_R R1    ./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...\n",
       "                           R2    ./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...\n",
       "H3N2_1205_T1_N_S517_N702_R R1    ./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...\n",
       "                           R2    ./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...\n",
       "H3N2_1205_T2_T_S517_N703_R R1    ./data/raw/H3N2_1205_T2_T_S517_N703_R_S3_L001_..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get path to raw FASTQ files sorted by read direction \n",
    "dat_df = ngs.generate_raw_fastq_df(sorted_sampid, data_folder)\n",
    "display (dat_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform ```FASTQC```\n",
    "\n",
    "```FastQC``` checks the quality of the raw FASTQ files (i.e. $\\ge$90% of reads has above acceptable quality score), determine the crop length for ```trimmomatic``` and ensure that there are negligible amount of adapter sequences present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform pre-trim FASTQC with minimum base quality 20 (change with --base_qual_threshold if needed)...\n",
      "\n",
      "#-- Presence of adapter sequence (max. proportion of reads) --#\n",
      "Nextera Transposase Sequence: 0.40%\n",
      "Illumina Small RNA 3' Adapter: 0.00%\n",
      "SOLID Small RNA Adapter: 0.00%\n",
      "Illumina Universal Adapter: 0.00%\n",
      "Illumina Small RNA 5' Adapter: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "      <th>percent_abv_qualthres</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampid</th>\n",
       "      <th>read</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">H3N2_1205_T0_T_S517_N701_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...</td>\n",
       "      <td>0.998310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...</td>\n",
       "      <td>0.997077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">H3N2_1205_T1_N_S517_N702_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...</td>\n",
       "      <td>0.996591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...</td>\n",
       "      <td>0.995069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T2_T_S517_N703_R</th>\n",
       "      <th>R1</th>\n",
       "      <td>./data/raw/H3N2_1205_T2_T_S517_N703_R_S3_L001_...</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             fpath  \\\n",
       "sampid                     read                                                      \n",
       "H3N2_1205_T0_T_S517_N701_R R1    ./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...   \n",
       "                           R2    ./data/raw/H3N2_1205_T0_T_S517_N701_R_S1_L001_...   \n",
       "H3N2_1205_T1_N_S517_N702_R R1    ./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...   \n",
       "                           R2    ./data/raw/H3N2_1205_T1_N_S517_N702_R_S2_L001_...   \n",
       "H3N2_1205_T2_T_S517_N703_R R1    ./data/raw/H3N2_1205_T2_T_S517_N703_R_S3_L001_...   \n",
       "\n",
       "                                 percent_abv_qualthres  start_pos  end_pos  \n",
       "sampid                     read                                             \n",
       "H3N2_1205_T0_T_S517_N701_R R1                 0.998310        1.0    251.0  \n",
       "                           R2                 0.997077        1.0    251.0  \n",
       "H3N2_1205_T1_N_S517_N702_R R1                 0.996591        1.0    251.0  \n",
       "                           R2                 0.995069        1.0    251.0  \n",
       "H3N2_1205_T2_T_S517_N703_R R1                 0.995238        1.0    251.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_df = ngs.pretrim_fastqc(dat_df, data_folder, base_qual_threshold)\n",
    "display (dat_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim low quality ends\n",
    "\n",
    "```Trimmomatic``` trims low quality ends and adapter sequences (if applicable). Crop length is determined by```FastQC``` earlier for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimming raw FASTQ sequences...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_pairs</th>\n",
       "      <th>both</th>\n",
       "      <th>both_prop</th>\n",
       "      <th>forward</th>\n",
       "      <th>reverse</th>\n",
       "      <th>dropped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T0_T_S517_N701_R</th>\n",
       "      <td>188180</td>\n",
       "      <td>187863</td>\n",
       "      <td>0.998315</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T1_N_S517_N702_R</th>\n",
       "      <td>212938</td>\n",
       "      <td>212211</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T2_T_S517_N703_R</th>\n",
       "      <td>205797</td>\n",
       "      <td>204817</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T3_T_S517_N704_R</th>\n",
       "      <td>216519</td>\n",
       "      <td>215527</td>\n",
       "      <td>0.995418</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T4_T_S517_N705_R</th>\n",
       "      <td>199923</td>\n",
       "      <td>199171</td>\n",
       "      <td>0.996239</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            total_pairs    both  both_prop  forward  reverse  \\\n",
       "sampid                                                                         \n",
       "H3N2_1205_T0_T_S517_N701_R       188180  187863   0.998315        0        3   \n",
       "H3N2_1205_T1_N_S517_N702_R       212938  212211   0.996586        3        7   \n",
       "H3N2_1205_T2_T_S517_N703_R       205797  204817   0.995238        2        7   \n",
       "H3N2_1205_T3_T_S517_N704_R       216519  215527   0.995418        6        9   \n",
       "H3N2_1205_T4_T_S517_N705_R       199923  199171   0.996239        2        3   \n",
       "\n",
       "                            dropped  \n",
       "sampid                               \n",
       "H3N2_1205_T0_T_S517_N701_R      314  \n",
       "H3N2_1205_T1_N_S517_N702_R      717  \n",
       "H3N2_1205_T2_T_S517_N703_R      971  \n",
       "H3N2_1205_T3_T_S517_N704_R      977  \n",
       "H3N2_1205_T4_T_S517_N705_R      747  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trimmed_df = ngs.trim_raw_fastq(dat_df, sorted_sampid, data_folder, trimmomatic_fpath, threadnum)\n",
    "display (trimmed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge paired-end reads with ```FLASH```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean prop of pairs merged: 85.08% (SD: 12.47%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>combined</th>\n",
       "      <th>percent_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T0_T_S517_N701_R</th>\n",
       "      <td>187863</td>\n",
       "      <td>174351</td>\n",
       "      <td>0.928075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T1_N_S517_N702_R</th>\n",
       "      <td>212211</td>\n",
       "      <td>200015</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T2_T_S517_N703_R</th>\n",
       "      <td>204817</td>\n",
       "      <td>191516</td>\n",
       "      <td>0.935059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T3_T_S517_N704_R</th>\n",
       "      <td>215527</td>\n",
       "      <td>204893</td>\n",
       "      <td>0.950660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3N2_1205_T4_T_S517_N705_R</th>\n",
       "      <td>199171</td>\n",
       "      <td>184334</td>\n",
       "      <td>0.925506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             total  combined  percent_combined\n",
       "sampid                                                        \n",
       "H3N2_1205_T0_T_S517_N701_R  187863    174351          0.928075\n",
       "H3N2_1205_T1_N_S517_N702_R  212211    200015          0.942529\n",
       "H3N2_1205_T2_T_S517_N703_R  204817    191516          0.935059\n",
       "H3N2_1205_T3_T_S517_N704_R  215527    204893          0.950660\n",
       "H3N2_1205_T4_T_S517_N705_R  199171    184334          0.925506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_df = ngs.merge_reads(dat_df, data_folder, sorted_sampid)\n",
    "display (merge_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read mapping\n",
    "\n",
    "```bowtie2``` to align the trimmed, merged reads to the reference sequence. \n",
    "\n",
    "Flags used for ```bowtie2```: \n",
    "```\n",
    "-x <refid> : Reference sequence to align by \n",
    "-X <int>   : If -X 100, a two 20-bp alignment + 60-bp gap would be valid but not if there is 61-bp gap \n",
    "-k <int>   : Searches for at most <int> of valid, distinct alignment for each read \n",
    "--local    : Does not require that the entire read align from one end to the other. Rather, some characters may be omitted (\"soft clipped\") from the ends in order to achieve the greatest possible alignment score. \n",
    "--very-sensitive : Same as -D 20 -R 3 -N 0 -L 20 -i S,1,0.50\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index reference sequences...\n",
      "\n",
      "Mapping reads with bowtie2...\n",
      "...done.\n"
     ]
    }
   ],
   "source": [
    "ngs.read_mapping_bt2(sorted_sampid, data_folder, influenza_gene_len, \n",
    "                     ref_fasta_fname, threadnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SAM files for patch and initial samples\n",
    "\n",
    "Some of the samples were re-sequenced (i.e. patch samples) due to low coverage for certain amplicons in the initial sequencing results. Here, we combined the SAM files for re-sequenced samples to their initial counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset meta_df index to subject_id and enrollment date\n",
    "try:\n",
    "    meta_df = meta_df.reset_index()\n",
    "except: \n",
    "    pass \n",
    "\n",
    "for subject_id in set(meta_df['subject_id']): \n",
    "    subject_meta_df = meta_df[meta_df['subject_id']==subject_id]\n",
    "    \n",
    "    for enrolD in sorted(set(subject_meta_df['enrolD'])): \n",
    "        enrolD_subject_meta_df = subject_meta_df[subject_meta_df['enrolD']==enrolD].sort_values(by='patch')\n",
    "        if len(enrolD_subject_meta_df) > 1: \n",
    "            sampid_list = list(enrolD_subject_meta_df['sampid'])\n",
    "            new_sampid = sampid_list[0] + 'P'\n",
    "            # concatenate sam files of initial and patch samples \n",
    "            if not os.path.isfile('{}/align/{}.sam.gz'.format(data_folder, new_sampid)):\n",
    "                cmd = ['cat'] + ['{}/align/{}.sam.gz'.format(data_folder, sampid) for sampid in sampid_list] + ['>', '{}/align/{}.sam.gz'.format(data_folder, new_sampid)]\n",
    "                subprocess.call(' '.join(cmd), shell=True)\n",
    "            \n",
    "            idx_list = list(enrolD_subject_meta_df.index)\n",
    "            # remove patch entry from meta df \n",
    "            meta_df = meta_df.drop(idx_list[-1])\n",
    "            # change initial entry with new_sampid \n",
    "            meta_df.at[idx_list[0], 'sampid'] = new_sampid\n",
    "            \n",
    "meta_df = meta_df.set_index('sampid').sort_index()\n",
    "meta_df.to_csv(\"./input/metadata_patched.csv\")\n",
    "sorted_sampid = list(meta_df.index)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse SAM files \n",
    "\n",
    "Quality filters:  \n",
    "- excluded all unmapped and non-primary read alignments\n",
    "- accept only bases with Q-score $\\ge$ ```base_qual_threshold``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapping_stats = ngs.parse_sam(sorted_sampid, sorted_refnames, data_folder, \n",
    "                              base_qual_threshold, max_indel_abs, max_indel_prop, \n",
    "                              threadnum=threadnum, plt_show=0)\n",
    "display (mapping_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort reads based on amplicons\n",
    "\n",
    "For all gene segments other than the matrix and non-structural gene segments, we performed six independent PCR amplication of three overlapping amplicons covering the entire gene. Here, we sort the mapped reads to the amplicon template they were based from by identifying unique sites that were covered by each individual amplicon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngs.sort_reads(sorted_sampid, primer_coords, gene_to_proteinorf, threadnum=threadnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tally base and codon counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngs.tally_bases(sorted_sampid, threadnum=threadnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant calling\n",
    "\n",
    "Other than the 2% frequency threshold, as per  (Illingworth, Bioinformatics, 2016), we compute a statistical threshold for a variant to be called. Suppose $q$ is  the minimum required base quality score, error rate will then be $p_e = 10^{-q/10}$. As such, if $n$ out of $N$ bases are called to a site, the probability that this event resulted from errors is modelled as: \n",
    "\n",
    "$p_{Err} = \\sum_{i=n}^{N}{\\begin{pmatrix}\n",
    "N \\\\\n",
    "i \n",
    "\\end{pmatrix}p_{e}^{i}(1-p_e)^{N-i}}$\n",
    "\n",
    "Variant is only called if $p_{Err}<0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_call_df = ngs.variant_calling(sorted_sampid, sorted_refnames, base_qual_threshold,\n",
    "                                      min_cov, min_var_prop, gene_to_proteinorf, err_tol, \n",
    "                                      ha_numbering_conversion=ha_numbering_conversion, \n",
    "                                      HAnum_subtype=HAnum_subtype, threadnum=threadnum)\n",
    "display (variant_call_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine basis for breadth of coverage \n",
    "\n",
    "Due to the inconsistent coverage across gene segments for certain samples, instead of using an arbitrarily defined minimum breadth of coverage, we find all polymorphic sites with >2% minority variants in at least 2 samples. A gene segment of a sample is determined to be amply covered if >70% of the polymorphic sites were meet minimum coverage requirements (>100x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    variant_call_df = variant_call_df.reset_index()\n",
    "except: \n",
    "    pass \n",
    "\n",
    "variant_call_df = variant_call_df.set_index('gene').sort_index()\n",
    "\n",
    "all_polymorphic_sites = []\n",
    "\n",
    "for gene in sorted_refnames: \n",
    "    \n",
    "    # filter for >2% of each gene\n",
    "    gene_vcf = variant_call_df.loc[gene].copy()\n",
    "    gene_vcf = gene_vcf.drop_duplicates(['nucpos', 'nuc_var', 'sampid'])\n",
    "    gene_vcf = gene_vcf[gene_vcf['nuc_prop']>=0.02]\n",
    "    \n",
    "    # get list of polymorphic sites and counts \n",
    "    polymorphic_sites = list(gene_vcf['nucpos'])\n",
    "    polymorphic_sites = {nucpos:polymorphic_sites.count(nucpos) for nucpos in set(polymorphic_sites)}\n",
    "    polymorphic_sites = pd.DataFrame.from_dict(polymorphic_sites.items())\n",
    "    polymorphic_sites.columns = ['nucpos', 'count']\n",
    "    \n",
    "    # all nucpos where mutations were found in >2 samples  \n",
    "    polymorphic_sites = polymorphic_sites[polymorphic_sites['count']>1]\n",
    "    polymorphic_sites['gene'] = gene\n",
    "    \n",
    "    all_polymorphic_sites.append(polymorphic_sites[['gene', 'nucpos']])\n",
    "\n",
    "all_polymorphic_sites = pd.concat(all_polymorphic_sites).set_index('gene').sort_index()\n",
    "display (all_polymorphic_sites.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleotide coverage plots for each patient \n",
    "\n",
    "Here, we also determined which gene segment of each sample met the required coverage breadth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standardise maximum y-value for plots \n",
    "ymax = -1\n",
    "for sampid in sorted_sampid: \n",
    "    try: \n",
    "        map_nuc_results = pd.read_csv('./results/map_nuc_results_{}.csv'.format(sampid))\n",
    "    except: \n",
    "        continue\n",
    "    if map_nuc_results['Coverage'].max() > ymax: \n",
    "        ymax = map_nuc_results['Coverage'].max()\n",
    "ymax = 10**int(np.ceil(np.log10(ymax)))\n",
    "\n",
    "# average coverage is based on a sliding window of 50 bp with stepsize of 25 bp\n",
    "sliding_window=50\n",
    "stepsize=25\n",
    "label_size = 12\n",
    "color_scheme = [\"#9e0142\", \"#d53e4f\", \"#f46d43\", \"#fdae61\", \"#fee08b\", \"#e6f598\", \"#abdda4\", \"#66c2a5\", \"#3288bd\", \"#5e4fa2\"][::-1]\n",
    "\n",
    "# array of sorted segment length \n",
    "sorted_gene_len = np.array([influenza_gene_len[refname] for refname in sorted(influenza_gene_len.keys())])\n",
    "\n",
    "# reindex meta_df based on subject_id and enrollment day \n",
    "meta_df = meta_df.reset_index().set_index(['subject_id', 'enrolD']).sort_index() \n",
    "\n",
    "# dataframe to plot overall distribution across all patients\n",
    "overall_gene_coverage_distribution = [] \n",
    "\n",
    "for subject_id in sorted(set(meta_df.index.get_level_values(0))): \n",
    "    print (subject_id)\n",
    "    \n",
    "    subject_meta_df = meta_df.loc[subject_id]\n",
    "    \n",
    "    # initialise coverage plot figure for each subject \n",
    "    with plt.style.context(\"default\"):\n",
    "        fig = plt.figure(figsize=(11.7, 4.1))#, constrained_layout=True)\n",
    "        spec = gridspec.GridSpec(1, 8, figure=fig, wspace=0.2, \n",
    "                                 width_ratios=sorted_gene_len/np.sum(sorted_gene_len))\n",
    "\n",
    "        axes = [] # list of subplots (by segments)\n",
    "        first_sample_bool = 1\n",
    "\n",
    "        for enrolD in sorted(set(subject_meta_df.index)): \n",
    "            enrolD_subject_meta_df = subject_meta_df.loc[enrolD]\n",
    "\n",
    "            try: \n",
    "                timepoint_label = \"D%i\"%(int(enrolD_subject_meta_df.timepoint))\n",
    "            except: \n",
    "                timepoint_label = \"T%i\"%(enrolD) \n",
    "\n",
    "            sampid = enrolD_subject_meta_df['sampid']\n",
    "            sample_type = enrolD_subject_meta_df['SampleType']\n",
    "\n",
    "            # read map_nuc_results \n",
    "            if os.path.isfile('./results/map_nuc_results_{}.csv'.format(sampid)): \n",
    "                # parse coverage/site quality results    \n",
    "                map_nuc_results = pd.read_csv('./results/map_nuc_results_{}.csv'.format(sampid), keep_default_na=False)\n",
    "            else: \n",
    "                print ('No mapped reads found for %s'%sampid)\n",
    "                continue \n",
    "\n",
    "            for _r, refname in enumerate(sorted(influenza_gene_len.keys())):\n",
    "\n",
    "                rdf = map_nuc_results[map_nuc_results['Gene']==refname]\n",
    "\n",
    "                refseq_len = influenza_gene_len[refname]\n",
    "                gene_start_pos = 1\n",
    "                gene_end_pos = gene_start_pos+refseq_len\n",
    "\n",
    "                # step size \n",
    "                x_values = np.arange(gene_start_pos, gene_end_pos, stepsize)\n",
    "                if x_values[-1] != gene_end_pos: \n",
    "                    x_values = np.append(x_values, gene_end_pos)\n",
    "\n",
    "                # compute mean coverage over sliding_window sized bins \n",
    "                y_values = np.zeros(len(x_values)-1)\n",
    "                mapdf = rdf[['Position', 'Coverage']].set_index('Position').sort_index()\n",
    "\n",
    "                # compute breadth of coverage \n",
    "                breadth = []\n",
    "                for idx, x_val in enumerate(x_values): \n",
    "                    if idx == 0:\n",
    "                        continue \n",
    "\n",
    "                    pos_range = range(int(np.max([0., x_val-sliding_window])), x_val)\n",
    "\n",
    "                    # compute mean coverage over 200bp bins \n",
    "                    try:\n",
    "                        mean_coverage = np.mean(mapdf.loc[pos_range])['Coverage']\n",
    "                    except: \n",
    "                        mean_coverage = np.zeros(len(pos_range))\n",
    "                        for _p, p in enumerate(pos_range): \n",
    "                            try: \n",
    "                                mean_coverage[_p] = mapdf.loc[p]['Coverage']\n",
    "                            except: \n",
    "                                continue \n",
    "                        mean_coverage = np.mean(mean_coverage)\n",
    "\n",
    "                    y_values[idx-1] = mean_coverage\n",
    "\n",
    "                    # breadth of coverage \n",
    "                    if mean_coverage >= min_cov: \n",
    "                        breadth += range(x_values[idx-1], x_val)\n",
    "\n",
    "                    # store computed mean coverage \n",
    "                    overall_gene_coverage_distribution.append({'gene':refname, 'pos':x_val, 'coverage':mean_coverage})\n",
    "\n",
    "                \"\"\"\n",
    "                # compute breadth of coverage \n",
    "                meta_df.loc[(subject_id, enrolD), refname] = len(breadth)/refseq_len\n",
    "                \"\"\"\n",
    "\n",
    "                num_overlapping_polymorphic_sites = len(set(all_polymorphic_sites.loc[refname, 'nucpos'])&set(rdf[rdf['Coverage']>=min_cov]['Position']))\n",
    "                meta_df.loc[(subject_id, enrolD), refname] = num_overlapping_polymorphic_sites/len(all_polymorphic_sites.loc[refname, 'nucpos']) \n",
    "\n",
    "                if first_sample_bool == 1:\n",
    "                    # add subplot for 1st sample \n",
    "                    ax = fig.add_subplot(spec[0,_r])\n",
    "                    ax.set_title(refname, fontsize=label_size) # title \n",
    "\n",
    "                    # plot min_cov line\n",
    "                    ax.plot(x_values[1:], \n",
    "                            np.zeros(len(x_values)-1)+min_cov, \n",
    "                            color='k', linestyle='--')\n",
    "                    axes.append(ax)\n",
    "                else: \n",
    "                    ax = axes[_r]\n",
    "\n",
    "                # plot coverage \n",
    "                # patch samples\n",
    "                if re.search('_P$', sampid):\n",
    "                    label = '{}-{} (patch)'.format(timepoint_label, sample_type)\n",
    "                    ax.plot(x_values[1:],\n",
    "                            y_values, '--',\n",
    "                            color=color_scheme[enrolD-1],\n",
    "                            label=label)\n",
    "                else: \n",
    "                    label = '{}-{}'.format(timepoint_label, sample_type)\n",
    "                    ax.plot(x_values[1:],\n",
    "                            y_values, \n",
    "                            color=color_scheme[enrolD-1],\n",
    "                            label=label)\n",
    "\n",
    "            if first_sample_bool == 1:\n",
    "                first_sample_bool = 0\n",
    "\n",
    "        for _ax, ax in enumerate(axes):\n",
    "            if _ax == 0: \n",
    "                ax.set_ylabel('Coverage')\n",
    "                ax.yaxis.label.set_fontsize(label_size)\n",
    "            else: \n",
    "                # remove y-axis label (sharey)\n",
    "                ax.tick_params(labelleft=False)\n",
    "\n",
    "            # gray facecolor for odd panels \n",
    "            if (_ax%2 != 0): \n",
    "                ax.set_facecolor(color='#d1d1d1')\n",
    "\n",
    "            # remove left and right spines \n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "            # set xlim and xtick labels\n",
    "            refname = sorted(influenza_gene_len.keys())[_ax]\n",
    "            refseq_len = influenza_gene_len[refname]\n",
    "            gene_start_pos = 1\n",
    "            gene_end_pos = gene_start_pos+refseq_len\n",
    "\n",
    "            if refseq_len > 2000: \n",
    "                ax.set_xticks(np.linspace(gene_start_pos,  gene_end_pos-1, 4))\n",
    "                ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 4)))\n",
    "            elif refseq_len > 1000: \n",
    "                ax.set_xticks(np.linspace(gene_start_pos,  gene_end_pos-1, 3))\n",
    "                ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 3)))\n",
    "            else: \n",
    "                ax.set_xticks(np.linspace(gene_start_pos, gene_end_pos-1, 2))\n",
    "                ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 2)))\n",
    "\n",
    "            # set ylim and yscale \n",
    "            ax.set_ylim((1, ymax))\n",
    "            ax.set_yscale('symlog')\n",
    "\n",
    "            # change tick size \n",
    "            ax.tick_params(axis='both', which='major', labelsize=label_size*0.8)\n",
    "\n",
    "            # change axis size \n",
    "            ax.xaxis.label.set_fontsize(label_size)\n",
    "\n",
    "        # x-axis label \n",
    "        fig.text(0.5, 0.01, 'Position', ha='center', fontsize=label_size)\n",
    "        plt.legend(loc='center left',  bbox_to_anchor=(1, 0.5))\n",
    "        #plt.tight_layout()\n",
    "        plt.savefig('./results/figures/coverage_plots_{}.pdf'.format(subject_id), \n",
    "                    bbox_inches='tight', pad_inches=0.)\n",
    "        plt.show()\n",
    "\n",
    "# convert overall_gene_coverage_distribution to dataframe \n",
    "overall_gene_coverage_distribution = pd.DataFrame.from_dict(overall_gene_coverage_distribution)\n",
    "overall_gene_coverage_distribution = overall_gene_coverage_distribution.set_index(['gene', 'pos']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot overall coverage across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise coverage plot figure \n",
    "with plt.style.context(\"default\"): \n",
    "    fig = plt.figure(figsize=(11.7, 4.1))#, constrained_layout=True)\n",
    "    spec = gridspec.GridSpec(1, 8, figure=fig, wspace=0.2, \n",
    "                             width_ratios=sorted_gene_len/np.sum(sorted_gene_len))\n",
    "\n",
    "    axes = [] # list of subplots (by segments)\n",
    "\n",
    "    # add subplot for 1st sample \n",
    "    for _r, refname in enumerate(sorted_refnames): \n",
    "        ax = fig.add_subplot(spec[0,_r])\n",
    "        ax.set_title(refname, fontsize=label_size) # title \n",
    "\n",
    "        # plot min_cov line\n",
    "        Y_array = []\n",
    "        X_array = np.array(sorted(set(overall_gene_coverage_distribution.loc[refname].index)))\n",
    "        for x_val in X_array:\n",
    "            Y_array.append(np.array(overall_gene_coverage_distribution.loc[(refname, x_val), 'coverage']))\n",
    "        Y_array = np.array(Y_array)\n",
    "\n",
    "        ax.plot(X_array, [100]*len(X_array), \"--\", color='#fcae91')\n",
    "\n",
    "        mu = np.median(Y_array, axis=1)\n",
    "        ax.plot(X_array, mu, color='#000000')\n",
    "        ax.fill_between(X_array, np.quantile(Y_array, 0.25, axis=1), \n",
    "                        np.quantile(Y_array, 0.75, axis=1), facecolor='#ef3b2c', alpha=0.5)\n",
    "        ax.fill_between(X_array, np.min(Y_array, axis=1), \n",
    "                        np.max(Y_array, axis=1), facecolor='#fcbba1', alpha=0.2)\n",
    "\n",
    "        axes.append(ax)\n",
    "\n",
    "    for _ax, ax in enumerate(axes):\n",
    "        if _ax == 0: \n",
    "            ax.set_ylabel('Coverage')\n",
    "            ax.yaxis.label.set_fontsize(label_size)\n",
    "        else: \n",
    "            # remove y-axis label (sharey)\n",
    "            ax.tick_params(labelleft=False)\n",
    "\n",
    "        # gray facecolor for odd panels \n",
    "        if (_ax%2 != 0): \n",
    "            ax.set_facecolor(color='#d1d1d1')\n",
    "\n",
    "        # remove left and right spines \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        # set xlim and xtick labels\n",
    "        refname = sorted(influenza_gene_len.keys())[_ax]\n",
    "        refseq_len = influenza_gene_len[refname]\n",
    "        gene_start_pos = 1\n",
    "        gene_end_pos = gene_start_pos+refseq_len\n",
    "\n",
    "        if refseq_len > 2000: \n",
    "            ax.set_xticks(np.linspace(gene_start_pos,  gene_end_pos-1, 4))\n",
    "            ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 4)))\n",
    "        elif refseq_len > 1000: \n",
    "            ax.set_xticks(np.linspace(gene_start_pos,  gene_end_pos-1, 3))\n",
    "            ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 3)))\n",
    "        else: \n",
    "            ax.set_xticks(np.linspace(gene_start_pos, gene_end_pos-1, 2))\n",
    "            ax.set_xticklabels(map(int, np.linspace(gene_start_pos,  gene_end_pos-1, 2)))\n",
    "\n",
    "        # set ylim and yscale \n",
    "        ax.set_ylim((1, ymax))\n",
    "        ax.set_yscale('symlog')\n",
    "\n",
    "        # change tick size \n",
    "        ax.tick_params(axis='both', which='major', labelsize=label_size*0.8)\n",
    "\n",
    "        # change axis size \n",
    "        ax.xaxis.label.set_fontsize(label_size)\n",
    "\n",
    "    # x-axis label \n",
    "    fig.text(0.5, 0.01, 'Position', ha='center', fontsize=label_size)\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('./results/figures/coverage_plots_overall.pdf', \n",
    "                bbox_inches='tight', pad_inches=0.)\n",
    "    plt.show()\n",
    "\n",
    "    # save meta_df with coverage breadth to results \n",
    "    meta_df.to_csv('./results/metadata_w_covbreadth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
